{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25048,"status":"ok","timestamp":1731624682118,"user":{"displayName":"Aryan Nath","userId":"00381514932192010045"},"user_tz":-330},"id":"ikSaVgzV0Zbb","outputId":"88a966d2-03a3-41ff-e4c9-c9328e3f48a3"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":716,"status":"ok","timestamp":1731624696197,"user":{"displayName":"Aryan Nath","userId":"00381514932192010045"},"user_tz":-330},"id":"V9QgLhuv1H2m"},"outputs":[],"source":["import os\n","# os.chdir(\"drive/My Drive/rf_signals/recordings_real/honda/model/MobileNet\")\n","os.chdir(\"drive/My Drive/model/MobileNet\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1712,"status":"ok","timestamp":1731624698957,"user":{"displayName":"Aryan Nath","userId":"00381514932192010045"},"user_tz":-330},"id":"SMtMuV_m1f5o","outputId":"68eea704-2d4e-45a9-b15f-b56eba0a0af8"},"outputs":[],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1807,"status":"ok","timestamp":1731446193933,"user":{"displayName":"Aryan Nath","userId":"02241134929809287163"},"user_tz":-330},"id":"rHDB1C5t1iAy","outputId":"3865801c-f727-42fb-e0cc-f8b7d0b0179e"},"outputs":[],"source":["!ls .."]},{"cell_type":"markdown","metadata":{"id":"3LxNyfjrA0F4"},"source":["### MobileNetV2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1386973,"status":"ok","timestamp":1731622320522,"user":{"displayName":"Aryan Nath","userId":"00381514932192010045"},"user_tz":-330},"id":"JXivnIHJ0RWN","outputId":"9fb950ea-6ef0-44c3-9e88-d6c6e7071cbb"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models, transforms\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","from PIL import Image\n","import time\n","\n","class DOCMobileNetV2(nn.Module):\n","    def __init__(self, num_classes):\n","        super(DOCMobileNetV2, self).__init__()\n","        self.mobilenet = models.mobilenet_v2(pretrained=True)\n","        num_features = self.mobilenet.classifier[1].in_features\n","        self.mobilenet.classifier[1] = nn.Linear(num_features, num_classes)\n","        self.losses = []\n","\n","    def forward(self, x):\n","        return self.mobilenet(x)\n","\n","class CompactnessLoss(nn.Module):\n","    def __init__(self):\n","        super(CompactnessLoss, self).__init__()\n","\n","    def forward(self, x):\n","        # n is the batch size, k is the number of features\n","        n, k = x.size()\n","        means = x.mean(dim=0, keepdim=True)\n","        squared_diff = (x - means).pow(2)\n","        variance = squared_diff.sum() / (n * k)\n","        return variance\n","\n","class DOCDataset(Dataset):\n","    def __init__(self, data, transform=None):\n","        self.data = data\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        signal, label = self.data[idx]\n","\n","        if isinstance(signal, np.ndarray):\n","            if signal.ndim == 3:\n","                signal = Image.fromarray(signal.astype(np.uint8), mode='RGB')\n","            elif signal.ndim == 2:\n","                signal = Image.fromarray(signal.astype(np.uint8), mode='L')\n","            else:\n","                raise TypeError(f\"Unexpected shape {signal.shape} for input data\")\n","\n","        if self.transform:\n","            signal = self.transform(signal)\n","\n","        return signal, label\n","\n","class DistillationLoss(nn.Module):\n","    def __init__(self, temperature=3.0):\n","        super(DistillationLoss, self).__init__()\n","        self.temperature = temperature\n","\n","    def forward(self, student_outputs, teacher_outputs, targets):\n","        soft_targets = nn.functional.softmax(teacher_outputs / self.temperature, dim=1)\n","        student_logits = nn.functional.log_softmax(student_outputs / self.temperature, dim=1)\n","        distillation_loss = nn.functional.kl_div(student_logits, soft_targets, reduction=\"batchmean\") * (self.temperature ** 2)\n","\n","        ce_loss = nn.CrossEntropyLoss()(student_outputs, targets)\n","        return distillation_loss + ce_loss\n","\n","def train_student(student_model, teacher_model, reference_loader, target_loader, num_epochs, learning_rate, lambda_val):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    student_model.to(device)\n","    teacher_model.to(device)\n","\n","    optimizer = optim.Adam(student_model.parameters(), lr=learning_rate)\n","    distillation_loss_fn = DistillationLoss(temperature=3.0)\n","    compactness_loss_fn = CompactnessLoss()\n","\n","    for epoch in range(num_epochs):\n","        student_model.losses.append([])\n","        student_model.train()\n","        desc_loss_accum = comp_loss_accum = dist_loss_accum = 0.0\n","\n","        for (ref_inputs, ref_labels), (target_inputs, _) in zip(reference_loader, target_loader):\n","            ref_inputs, ref_labels = ref_inputs.to(device), ref_labels.to(device)\n","            target_inputs = target_inputs.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            # Teacher's output on the reference inputs\n","            with torch.no_grad():\n","                teacher_outputs = teacher_model(ref_inputs)\n","\n","            # Student's output on the reference inputs\n","            student_outputs = student_model(ref_inputs)\n","            dist_loss = distillation_loss_fn(student_outputs, teacher_outputs, ref_labels)\n","            dist_loss.backward(retain_graph=True)\n","            dist_grads = [p.grad.clone() for p in student_model.parameters()]\n","            dist_loss_accum += dist_loss.item()\n","            desc_loss = nn.CrossEntropyLoss()(student_outputs, ref_labels)\n","            # desc_loss_accum += desc_loss.item()\n","\n","            # Target dataset forward pass with compactness loss\n","            optimizer.zero_grad()\n","            student_target_outputs = student_model(target_inputs)\n","            comp_loss = compactness_loss_fn(student_target_outputs)\n","            comp_loss.backward()\n","            comp_grads = [p.grad.clone() for p in student_model.parameters()]\n","            comp_loss_accum += comp_loss.item()\n","\n","            # Combine gradients from distillation and compactness loss\n","            for p, dg, cg in zip(student_model.parameters(), dist_grads, comp_grads):\n","                p.grad = (dg + cg) / 2\n","\n","            optimizer.step()\n","            student_model.losses[-1].append((dist_loss.item(), comp_loss.item(),desc_loss.item()))\n","\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Distillation Loss: {dist_loss_accum:.4f}, Compactness Loss: {comp_loss_accum:.4f}\")\n","\n","teacher_model = torch.jit.load(\"../ResNet/resnet_fft_aug.pt\")\n","teacher_model.eval()  # set teacher model to evaluation mode\n","\n","num_classes = 1000  # same number of classes as in ImageNet\n","model = DOCMobileNetV2(num_classes)\n","\n","# datasets: legitimate, reconstructed, attack, augmented legitimate signals\n","dataset_type = ['constellation/','fft/']\n","datasets_directory = '../datasets/' + dataset_type[1]\n","\n","print(\"Dataset type:\", dataset_type[1][:-1])\n","print(\"Loading datasets...\")\n","\n","with open(datasets_directory + 'reconstructed7.npy','rb') as f:\n","    reconstructed_attack = []\n","    signal = np.load(f)\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            reconstructed_attack.append(signal)\n","        except:\n","            break\n","\n","with open(datasets_directory + 'legitimate.npy','rb') as f:\n","    legitimate = []\n","    signal = np.load(f)\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            legitimate.append(signal)\n","        except:\n","            break\n","\n","with open(datasets_directory + 'attack1.npy','rb') as f:\n","    attack1 = []\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            attack1.append(signal)\n","        except:\n","            break\n","\n","with open(datasets_directory + 'attack2.npy','rb') as f:\n","    attack2 = []\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            attack2.append(signal)\n","        except:\n","            break\n","\n","with open(datasets_directory + 'augmented_legitimate7.npy','rb') as f:\n","    augmented_legitimate = []\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            augmented_legitimate.append(signal)\n","        except:\n","            break\n","legitimate = [(signal, 0) for signal in legitimate]\n","augmented_legitimate = [(signal, 0) for signal in augmented_legitimate]\n","reconstructed_attack = [(signal, 1) for signal in reconstructed_attack]\n","attack1 = [(signal, 1) for signal in attack1]\n","attack2 = [(signal, 1) for signal in attack2]\n","reference_dataset = augmented_legitimate + reconstructed_attack\n","target_dataset = augmented_legitimate\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor()\n","])\n","\n","reference_dataset = DOCDataset(reference_dataset, transform=transform)\n","reference_loader = DataLoader(reference_dataset, batch_size=32, shuffle=True)\n","\n","target_dataset = DOCDataset(target_dataset, transform=transform)\n","target_loader = DataLoader(target_dataset, batch_size=32, shuffle=True)\n","\n","num_epochs = 120\n","learning_rate = 0.0001\n","lambda_val = 0.5\n","\n","print(\"dataset size:\",len(reference_dataset),len(target_dataset))\n","\n","start = time.time()\n","train_student(model, teacher_model, reference_loader, target_loader, num_epochs, learning_rate, lambda_val)\n","print(\"training runtime:\",time.time()-start)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4030,"status":"ok","timestamp":1731475123120,"user":{"displayName":"Aryan Nath","userId":"02241134929809287163"},"user_tz":-330},"id":"r1acz1l-BZ8Q","outputId":"34180dd1-a10a-47b1-ce6b-f193e4d3949a"},"outputs":[],"source":["!pip install pytorchcv"]},{"cell_type":"markdown","metadata":{"id":"TgmkpCfbA3jF"},"source":["### MobileNetV1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6667,"status":"ok","timestamp":1731612881764,"user":{"displayName":"Aryan Nath","userId":"00381514932192010045"},"user_tz":-330},"id":"nd1z7tFdK27V","outputId":"7db79411-4fdc-4787-cf42-fef61cd8595f"},"outputs":[],"source":["!pip install pytorchcv"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1379170,"status":"ok","timestamp":1731615068330,"user":{"displayName":"Aryan Nath","userId":"00381514932192010045"},"user_tz":-330},"id":"dKAaM3yOA5J0","outputId":"ced078b4-4b30-462c-d9f9-5e0bfc91155c"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from pytorchcv.model_provider import get_model as ptcv_get_model\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","from PIL import Image\n","import time\n","\n","class DOCMobileNetV1(nn.Module):\n","    def __init__(self, num_classes):\n","        super(DOCMobileNetV1, self).__init__()\n","        # Load pretrained MobileNetV1 from pytorchcv\n","        self.mobilenet = ptcv_get_model(\"mobilenet_w1\", pretrained=True)\n","        num_features = self.mobilenet.output.in_features\n","        self.mobilenet.output = nn.Linear(num_features, num_classes)\n","        self.losses = []\n","\n","    def forward(self, x):\n","        return self.mobilenet(x)\n","\n","class CompactnessLoss(nn.Module):\n","    def __init__(self):\n","        super(CompactnessLoss, self).__init__()\n","\n","    def forward(self, x):\n","        # n is the batch size, k is the number of features\n","        n, k = x.size()\n","        means = x.mean(dim=0, keepdim=True)\n","        squared_diff = (x - means).pow(2)\n","        variance = squared_diff.sum() / (n * k)\n","        return variance\n","\n","class DOCDataset(Dataset):\n","    def __init__(self, data, transform=None):\n","        self.data = data\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        signal, label = self.data[idx]\n","\n","        if isinstance(signal, np.ndarray):\n","            if signal.ndim == 3:\n","                signal = Image.fromarray(signal.astype(np.uint8), mode='RGB')\n","            elif signal.ndim == 2:\n","                signal = Image.fromarray(signal.astype(np.uint8), mode='L')\n","            else:\n","                raise TypeError(f\"Unexpected shape {signal.shape} for input data\")\n","\n","        if self.transform:\n","            signal = self.transform(signal)\n","\n","        return signal, label\n","\n","class DistillationLoss(nn.Module):\n","    def __init__(self, temperature=3.0):\n","        super(DistillationLoss, self).__init__()\n","        self.temperature = temperature\n","\n","    def forward(self, student_outputs, teacher_outputs, targets):\n","        soft_targets = nn.functional.softmax(teacher_outputs / self.temperature, dim=1)\n","        student_logits = nn.functional.log_softmax(student_outputs / self.temperature, dim=1)\n","        distillation_loss = nn.functional.kl_div(student_logits, soft_targets, reduction=\"batchmean\") * (self.temperature ** 2)\n","\n","        ce_loss = nn.CrossEntropyLoss()(student_outputs, targets)\n","        return distillation_loss + ce_loss\n","\n","def train_student(student_model, teacher_model, reference_loader, target_loader, num_epochs, learning_rate, lambda_val):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    student_model.to(device)\n","    teacher_model.to(device)\n","\n","    optimizer = optim.Adam(student_model.parameters(), lr=learning_rate)\n","    distillation_loss_fn = DistillationLoss(temperature=3.0)\n","    compactness_loss_fn = CompactnessLoss()\n","\n","    for epoch in range(num_epochs):\n","        student_model.losses.append([])\n","        student_model.train()\n","        desc_loss_accum = comp_loss_accum = dist_loss_accum = 0.0\n","\n","        for (ref_inputs, ref_labels), (target_inputs, _) in zip(reference_loader, target_loader):\n","            ref_inputs, ref_labels = ref_inputs.to(device), ref_labels.to(device)\n","            target_inputs = target_inputs.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            # Teacher's output on the reference inputs\n","            with torch.no_grad():\n","                teacher_outputs = teacher_model(ref_inputs)\n","\n","            # Student's output on the reference inputs\n","            student_outputs = student_model(ref_inputs)\n","            dist_loss = distillation_loss_fn(student_outputs, teacher_outputs, ref_labels)\n","            dist_loss.backward(retain_graph=True)\n","            dist_grads = [p.grad.clone() for p in student_model.parameters()]\n","            dist_loss_accum += dist_loss.item()\n","            desc_loss = nn.CrossEntropyLoss()(student_outputs, ref_labels)\n","            # desc_loss_accum += desc_loss.item()\n","\n","            # Target dataset forward pass with compactness loss\n","            optimizer.zero_grad()\n","            student_target_outputs = student_model(target_inputs)\n","            comp_loss = compactness_loss_fn(student_target_outputs)\n","            comp_loss.backward()\n","            comp_grads = [p.grad.clone() for p in student_model.parameters()]\n","            comp_loss_accum += comp_loss.item()\n","\n","            # Combine gradients from distillation and compactness loss\n","            for p, dg, cg in zip(student_model.parameters(), dist_grads, comp_grads):\n","                p.grad = (dg + cg) / 2\n","\n","            optimizer.step()\n","            student_model.losses[-1].append((dist_loss.item(), comp_loss.item(),desc_loss.item()))\n","\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Distillation Loss: {dist_loss_accum:.4f}, Compactness Loss: {comp_loss_accum:.4f}\")\n","\n","teacher_model = torch.jit.load(\"../ResNet/resnet_fft_aug.pt\")\n","teacher_model.eval()  # set teacher model to evaluation mode\n","\n","num_classes = 1000  # same number of classes as in ImageNet\n","model = DOCMobileNetV1(num_classes)\n","\n","# datasets: legitimate, reconstructed, attack, augmented legitimate signals\n","dataset_type = ['constellation/','fft/']\n","datasets_directory = '../datasets/' + dataset_type[1]\n","\n","print(\"Dataset type:\", dataset_type[1][:-1])\n","print(\"Loading datasets...\")\n","\n","with open(datasets_directory + 'reconstructed7.npy','rb') as f:\n","    reconstructed_attack = []\n","    signal = np.load(f)\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            reconstructed_attack.append(signal)\n","        except:\n","            break\n","\n","with open(datasets_directory + 'legitimate.npy','rb') as f:\n","    legitimate = []\n","    signal = np.load(f)\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            legitimate.append(signal)\n","        except:\n","            break\n","\n","with open(datasets_directory + 'attack1.npy','rb') as f:\n","    attack1 = []\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            attack1.append(signal)\n","        except:\n","            break\n","\n","with open(datasets_directory + 'attack2.npy','rb') as f:\n","    attack2 = []\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            attack2.append(signal)\n","        except:\n","            break\n","\n","with open(datasets_directory + 'augmented_legitimate7.npy','rb') as f:\n","    augmented_legitimate = []\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            augmented_legitimate.append(signal)\n","        except:\n","            break\n","legitimate = [(signal, 0) for signal in legitimate]\n","augmented_legitimate = [(signal, 0) for signal in augmented_legitimate]\n","reconstructed_attack = [(signal, 1) for signal in reconstructed_attack]\n","attack1 = [(signal, 1) for signal in attack1]\n","attack2 = [(signal, 1) for signal in attack2]\n","reference_dataset = augmented_legitimate + reconstructed_attack\n","target_dataset = augmented_legitimate\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor()\n","])\n","\n","reference_dataset = DOCDataset(reference_dataset, transform=transform)\n","reference_loader = DataLoader(reference_dataset, batch_size=32, shuffle=True)\n","\n","target_dataset = DOCDataset(target_dataset, transform=transform)\n","target_loader = DataLoader(target_dataset, batch_size=32, shuffle=True)\n","\n","num_epochs = 120\n","learning_rate = 0.0001\n","lambda_val = 0.5\n","\n","print(\"dataset size:\",len(reference_dataset),len(target_dataset))\n","\n","start = time.time()\n","# train_student(model, teacher_model, reference_loader, target_loader, num_epochs, learning_rate, lambda_val)\n","print(\"training runtime:\",time.time()-start)"]},{"cell_type":"markdown","metadata":{"id":"EaHpvnK_Kr28"},"source":["### QAT MobileNetV1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":563},"executionInfo":{"elapsed":711860,"status":"error","timestamp":1731446953364,"user":{"displayName":"Aryan Nath","userId":"02241134929809287163"},"user_tz":-330},"id":"-LimP1wyKtkR","outputId":"917ad0c8-800d-436d-89cd-4347d95f1f52"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from pytorchcv.model_provider import get_model as ptcv_get_model\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","from PIL import Image\n","import time\n","from torch.quantization import QuantStub, DeQuantStub, fuse_modules, prepare_qat, convert\n","\n","class DOCMobileNetV1(nn.Module):\n","    def __init__(self, num_classes):\n","        super(DOCMobileNetV1, self).__init__()\n","        base_model = ptcv_get_model(\"mobilenet_w1\", pretrained=True)\n","\n","        # Restructure the model for QAT\n","        self.features = base_model.features\n","        self.classifier = base_model.output\n","\n","        # Adjust the classifier for your number of classes\n","        num_features = self.classifier.in_features\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(p=0.2),\n","            nn.Linear(num_features, num_classes)\n","        )\n","\n","        # Add quantization stubs\n","        self.quant = QuantStub()\n","        self.dequant = DeQuantStub()\n","\n","        self.losses = []\n","\n","    def forward(self, x):\n","        x = self.quant(x)\n","        x = self.features(x)\n","        # Global average pooling\n","        x = torch.mean(x, dim=(2, 3))\n","        x = self.classifier(x)\n","        x = self.dequant(x)\n","        return x\n","\n","    def fuse_model(self):\n","        \"\"\"\n","        Fuse Conv+BN+ReLU modules in the model for better quantization\n","        \"\"\"\n","        for m in self.modules():\n","            if type(m) == nn.Sequential:\n","                for i in range(len(m) - 2):\n","                    if (isinstance(m[i], nn.Conv2d) and\n","                        isinstance(m[i + 1], nn.BatchNorm2d) and\n","                        isinstance(m[i + 2], nn.ReLU)):\n","                        torch.quantization.fuse_modules(m, [str(i), str(i + 1), str(i + 2)], inplace=True)\n","\n","class CompactnessLoss(nn.Module):\n","    def __init__(self):\n","        super(CompactnessLoss, self).__init__()\n","\n","    def forward(self, x):\n","        # n is the batch size, k is the number of features\n","        n, k = x.size()\n","        means = x.mean(dim=0, keepdim=True)\n","        squared_diff = (x - means).pow(2)\n","        variance = squared_diff.sum() / (n * k)\n","        return variance\n","\n","class DOCDataset(Dataset):\n","    def __init__(self, data, transform=None):\n","        self.data = data\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        signal, label = self.data[idx]\n","\n","        if isinstance(signal, np.ndarray):\n","            if signal.ndim == 3:\n","                signal = Image.fromarray(signal.astype(np.uint8), mode='RGB')\n","            elif signal.ndim == 2:\n","                signal = Image.fromarray(signal.astype(np.uint8), mode='L')\n","            else:\n","                raise TypeError(f\"Unexpected shape {signal.shape} for input data\")\n","\n","        if self.transform:\n","            signal = self.transform(signal)\n","\n","        return signal, label\n","\n","class DistillationLoss(nn.Module):\n","    def __init__(self, temperature=3.0):\n","        super(DistillationLoss, self).__init__()\n","        self.temperature = temperature\n","\n","    def forward(self, student_outputs, teacher_outputs, targets):\n","        soft_targets = nn.functional.softmax(teacher_outputs / self.temperature, dim=1)\n","        student_logits = nn.functional.log_softmax(student_outputs / self.temperature, dim=1)\n","        distillation_loss = nn.functional.kl_div(student_logits, soft_targets, reduction=\"batchmean\") * (self.temperature ** 2)\n","\n","        ce_loss = nn.CrossEntropyLoss()(student_outputs, targets)\n","        return distillation_loss + ce_loss\n","\n","def train_student(student_model, teacher_model, reference_loader, target_loader, num_epochs, learning_rate, lambda_val):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # Move models to CPU for QAT (QAT requires CPU)\n","    student_model = student_model.cpu()\n","    teacher_model = teacher_model.cpu()\n","\n","    optimizer = optim.Adam(student_model.parameters(), lr=learning_rate)\n","    distillation_loss_fn = DistillationLoss(temperature=3.0)\n","    compactness_loss_fn = CompactnessLoss()\n","\n","    # Prepare model for QAT\n","    student_model.train()\n","\n","    # Fuse layers\n","    student_model.fuse_model()\n","\n","    # Set QAT configuration\n","    student_model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n","\n","    # Prepare the model for QAT\n","    prepare_qat(student_model, inplace=True)\n","\n","    for epoch in range(num_epochs):\n","        student_model.losses.append([])\n","        student_model.train()\n","        desc_loss_accum = comp_loss_accum = dist_loss_accum = 0.0\n","\n","        for batch_idx, ((ref_inputs, ref_labels), (target_inputs, _)) in enumerate(zip(reference_loader, target_loader)):\n","            # Move data to CPU for QAT\n","            ref_inputs, ref_labels = ref_inputs.cpu(), ref_labels.cpu()\n","            target_inputs = target_inputs.cpu()\n","\n","            optimizer.zero_grad()\n","\n","            # Teacher's output\n","            with torch.no_grad():\n","                teacher_outputs = teacher_model(ref_inputs)\n","\n","            # Student's output\n","            student_outputs = student_model(ref_inputs)\n","            dist_loss = distillation_loss_fn(student_outputs, teacher_outputs, ref_labels)\n","            dist_loss.backward(retain_graph=True)\n","            desc_grads = [p.grad.clone() for p in student_model.parameters()]\n","            dist_loss_accum += dist_loss.item()\n","\n","            # Target dataset forward pass\n","            optimizer.zero_grad()\n","            student_target_outputs = student_model(target_inputs)\n","            comp_loss = compactness_loss_fn(student_target_outputs)\n","            comp_loss.backward()\n","            comp_grads = [p.grad.clone() for p in student_model.parameters()]\n","            comp_loss_accum += comp_loss.item()\n","\n","            # Combine gradients\n","            for p, dg, cg in zip(student_model.parameters(), desc_grads, comp_grads):\n","                if p.grad is not None:\n","                    p.grad = (dg + lambda_val * cg)\n","\n","            optimizer.step()\n","            student_model.losses[-1].append((dist_loss.item(), comp_loss.item()))\n","\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Distillation Loss: {dist_loss_accum:.4f}, Compactness Loss: {comp_loss_accum:.4f}\")\n","\n","    # Convert to quantized model\n","    student_model.eval()\n","    student_model = torch.quantization.convert(student_model, inplace=True)\n","\n","    return student_model\n","\n","teacher_model = torch.jit.load(\"../ResNet/resnet_fft.pt\")\n","teacher_model.eval()  # set teacher model to evaluation mode\n","\n","num_classes = 1000  # same number of classes as in ImageNet\n","model = DOCMobileNetV1(num_classes)\n","\n","# datasets: legitimate, reconstructed, attack, augmented legitimate signals\n","dataset_type = ['constellation/','fft/']\n","datasets_directory = '../datasets/' + dataset_type[1]\n","\n","print(\"Dataset type:\", dataset_type[1][:-1])\n","print(\"Loading datasets...\")\n","\n","with open(datasets_directory + 'reconstructed.npy','rb') as f:\n","    reconstructed_attack = []\n","    signal = np.load(f)\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            reconstructed_attack.append(signal)\n","        except:\n","            break\n","\n","with open(datasets_directory + 'legitimate.npy','rb') as f:\n","    legitimate = []\n","    signal = np.load(f)\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            legitimate.append(signal)\n","        except:\n","            break\n","\n","with open(datasets_directory + 'attack1.npy','rb') as f:\n","    attack1 = []\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            attack1.append(signal)\n","        except:\n","            break\n","\n","with open(datasets_directory + 'attack2.npy','rb') as f:\n","    attack2 = []\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            attack2.append(signal)\n","        except:\n","            break\n","\n","with open(datasets_directory + 'augmented_legitimate.npy','rb') as f:\n","    augmented_legitimate = []\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            augmented_legitimate.append(signal)\n","        except:\n","            break\n","legitimate = [(signal, 0) for signal in legitimate]\n","augmented_legitimate = [(signal, 0) for signal in augmented_legitimate]\n","reconstructed_attack = [(signal, 1) for signal in reconstructed_attack]\n","attack1 = [(signal, 1) for signal in attack1]\n","attack2 = [(signal, 1) for signal in attack2]\n","reference_dataset = augmented_legitimate + reconstructed_attack\n","target_dataset = augmented_legitimate\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor()\n","])\n","\n","reference_dataset = DOCDataset(reference_dataset, transform=transform)\n","reference_loader = DataLoader(reference_dataset, batch_size=32, shuffle=True)\n","\n","target_dataset = DOCDataset(target_dataset, transform=transform)\n","target_loader = DataLoader(target_dataset, batch_size=32, shuffle=True)\n","\n","num_epochs = 120\n","learning_rate = 0.0001\n","lambda_val = 0.5\n","\n","print(\"dataset size:\",len(reference_dataset),len(target_dataset))\n","\n","start = time.time()\n","train_student(model, teacher_model, reference_loader, target_loader, num_epochs, learning_rate, lambda_val)\n","print(\"training runtime:\",time.time()-start)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_502Ku7HSX2"},"outputs":[],"source":["torch.save(model.state_dict(), \"mobilenetv1.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":456,"status":"ok","timestamp":1731444175970,"user":{"displayName":"Aryan Nath","userId":"02241134929809287163"},"user_tz":-330},"id":"ttH5Rx8fHWfG","outputId":"8263ca31-5432-4204-9c36-86ac812dc36d"},"outputs":[],"source":["!ls"]},{"cell_type":"markdown","metadata":{"id":"GCkDQCwbKm0A"},"source":["### Quantization on mobilenetv1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51171,"status":"ok","timestamp":1731444266302,"user":{"displayName":"Aryan Nath","userId":"02241134929809287163"},"user_tz":-330},"id":"H6UYJQNUG0ji","outputId":"20f41199-176b-40de-bb29-842d1ca423b0"},"outputs":[],"source":["import torch.quantization as quant\n","\n","# Prepare the model for quantization\n","def quantize_model(model):\n","    model.eval()\n","\n","    # 1. Fuse any necessary layers (if applicable). For MobileNet, this may not be required.\n","    # model.fuse_model() # Uncomment if layer fusion is required\n","\n","    # 2. Specify quantization configuration\n","    model.qconfig = quant.get_default_qconfig('fbgemm')\n","\n","    # 3. Prepare the model for static quantization\n","    quant.prepare(model, inplace=True)\n","\n","    # Calibrate the model with representative data from the target dataset\n","    with torch.no_grad():\n","        for inputs, _ in target_loader:\n","            model(inputs)\n","\n","    # 4. Convert to quantized version\n","    quant.convert(model, inplace=True)\n","\n","    return model\n","\n","quantized_model = quantize_model(model)\n","\n","quantized_model_path = 'quantized_mobilenetv1.pth'\n","torch.save(quantized_model.state_dict(), quantized_model_path)\n","quantized_size = os.path.getsize(quantized_model_path) / (1024 * 1024)\n","print(f\"Quantized model size: {quantized_size:.2f} MB\")\n"]},{"cell_type":"markdown","metadata":{"id":"T7Ix8YVJWKqZ"},"source":["Load the saved quantized model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":617},"executionInfo":{"elapsed":14200,"status":"error","timestamp":1731498423039,"user":{"displayName":"Aryan Nath","userId":"02241134929809287163"},"user_tz":-330},"id":"mjxLTQ_ARGdt","outputId":"bb55f950-6df9-45dc-b0e6-a5d2d4303fef"},"outputs":[],"source":["import torch\n","from torchvision import models\n","import torch.nn as nn\n","import os\n","\n","class DOCMobileNetV2(nn.Module):\n","    def __init__(self, num_classes):\n","        super(DOCMobileNetV2, self).__init__()\n","        self.mobilenet = models.mobilenet_v2(pretrained=True)\n","        num_features = self.mobilenet.classifier[1].in_features\n","        self.mobilenet.classifier[1] = nn.Linear(num_features, num_classes)\n","        self.losses = []\n","\n","    def forward(self, x):\n","        return self.mobilenet(x)\n","\n","def load_quantized_model(path, num_classes):\n","    model = DOCMobileNetV2(num_classes)\n","    model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n","\n","    torch.quantization.prepare(model, inplace=True)\n","    torch.quantization.convert(model, inplace=True)\n","\n","    model.load_state_dict(torch.load(path))\n","    model.eval()\n","\n","    return model\n","\n","quantized_model_path = 'quantized_mobilenetv1.pth'\n","num_classes = 1000\n","quantized_model = load_quantized_model(quantized_model_path, num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i65kGgLp_sS_"},"outputs":[],"source":["# from pytorchcv.model_provider import get_model as ptcv_get_model\n","# import torch\n","# import torch.quantization as quant\n","\n","# # Prepare the model for quantization\n","# def quantize_model(model):\n","#     model.eval()\n","\n","#     # 1. Fuse any necessary layers (if applicable). For MobileNet, this may not be required.\n","#     # model.fuse_model() # Uncomment if layer fusion is required\n","\n","#     # 2. Specify quantization configuration\n","#     model.qconfig = quant.get_default_qconfig('fbgemm')\n","\n","#     # 3. Prepare the model for static quantization\n","#     quant.prepare(model, inplace=True)\n","\n","#     # Calibrate the model with representative data from the target dataset\n","#     with torch.no_grad():\n","#         for inputs, _ in target_loader:\n","#             model(inputs)\n","\n","#     # 4. Convert to quantized version\n","#     quant.convert(model, inplace=True)\n","\n","#     return model\n","\n","\n","# model = ptcv_get_model(\"mobilenet_w1\",pretrained=True)\n","# # Apply quantization to your MobileNetV1 model\n","# quantized_model1 = quantize_model(model)\n","\n","# # Verify storage requirement by saving the model\n","# quantize_model1.weights()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":6,"status":"ok","timestamp":1731444908847,"user":{"displayName":"Aryan Nath","userId":"02241134929809287163"},"user_tz":-330},"id":"I_AR15NEIj9m","outputId":"0548487a-9067-4ad5-a840-88493d22f7e4"},"outputs":[],"source":["quantized_model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":404,"status":"ok","timestamp":1731616782720,"user":{"displayName":"Aryan Nath","userId":"00381514932192010045"},"user_tz":-330},"id":"W5Mo0jEUZuVs","outputId":"6ed497b8-428c-481b-eac9-96348bc9eb3e"},"outputs":[],"source":["model_to_script = DOCMobileNetV1(num_classes)\n","model_to_script.load_state_dict(model.state_dict())"]},{"cell_type":"markdown","metadata":{"id":"VVk2h2J0ana8"},"source":["augmented mobilenetv1 losses"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":1311,"status":"ok","timestamp":1731617013380,"user":{"displayName":"Aryan Nath","userId":"00381514932192010045"},"user_tz":-330},"id":"99qoB72KaqwZ","outputId":"eca66812-f16b-4ab1-8984-8f8619dcb237"},"outputs":[],"source":["model.losses"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"executionInfo":{"elapsed":491,"status":"error","timestamp":1731617047757,"user":{"displayName":"Aryan Nath","userId":"00381514932192010045"},"user_tz":-330},"id":"xv0Ci7MViBY0","outputId":"b5582a61-2533-4126-d4a9-9b3d241fe801"},"outputs":[],"source":["import torch\n","\n","model_to_script = model_to_script.cpu()\n","traced_model = torch.jit.script(model_to_script)\n","traced_model.save(\"mobilenetv1_fft_aug.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EOsSNdGcbShQ"},"outputs":[],"source":["# import pickle\n","\n","# with open('mobilenetv1_fft_aug.pkl','wb') as f:\n","#   pickle.dump(model,f)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":455,"status":"ok","timestamp":1731623723377,"user":{"displayName":"Aryan Nath","userId":"00381514932192010045"},"user_tz":-330},"id":"hFau-ZCX0O2L"},"outputs":[],"source":["# import pickle\n","\n","model.to('cpu')\n","# with open('mobilenetv2_fft_aug.pkl','wb') as f:\n","#   pickle.dump(model,f)"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["import pickle\n","import torch\n","import torch.nn as nn\n","import pytorchcv\n","\n","class DOCMobileNetV1(nn.Module):\n","    def __init__(self, num_classes):\n","        super(DOCMobileNetV1, self).__init__()\n","        # Load pretrained MobileNetV1 from pytorchcv\n","        self.mobilenet = ptcv_get_model(\"mobilenet_w1\", pretrained=True)\n","        num_features = self.mobilenet.output.in_features\n","        self.mobilenet.output = nn.Linear(num_features, num_classes)\n","        self.losses = []\n","\n","    def forward(self, x):\n","        return self.mobilenet(x)\n","    \n","class DOCMobileNetV2(nn.Module):\n","    def __init__(self, num_classes):\n","        super(DOCMobileNetV2, self).__init__()\n","        self.mobilenet = models.mobilenet_v2(pretrained=True)\n","        num_features = self.mobilenet.classifier[1].in_features\n","        self.mobilenet.classifier[1] = nn.Linear(num_features, num_classes)\n","        self.losses = []\n","\n","    def forward(self, x):\n","        return self.mobilenet(x)\n","\n","with open('mobilenetv1_fft_aug.pkl','rb') as f:\n","  mb1 = pickle.load(f)\n","\n","with open('mobilenetv2_fft_aug.pkl','rb') as f:\n","  mb2 = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":341},"executionInfo":{"elapsed":2664,"status":"error","timestamp":1731624898880,"user":{"displayName":"Aryan Nath","userId":"00381514932192010045"},"user_tz":-330},"id":"ejgTeokCbnvY","outputId":"2cb573dc-05ae-41aa-8f65-5599f9f93e1d"},"outputs":[],"source":["# import pickle\n","# import torch.nn as nn\n","# import torch\n","\n","# class DOCMobileNetV2(nn.Module):\n","#     def __init__(self, num_classes):\n","#         super(DOCMobileNetV2, self).__init__()\n","#         self.mobilenet = models.mobilenet_v2(pretrained=True)\n","#         num_features = self.mobilenet.classifier[1].in_features\n","#         self.mobilenet.classifier[1] = nn.Linear(num_features, num_classes)\n","#         self.losses = []\n","\n","#     def forward(self, x):\n","#         return self.mobilenet(x)\n","\n","# model = torch.jit.load(\"mobilenetv2_fft.pkl\", map_location=torch.device('cpu'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x34gcTIniC-Y"},"outputs":[],"source":["import torch\n","\n","model = torch.jit.load(\"mobilenetv2_fft.pt\", map_location=torch.device('cpu'))\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7361,"status":"ok","timestamp":1731624428405,"user":{"displayName":"Aryan Nath","userId":"00381514932192010045"},"user_tz":-330},"id":"wDHHIMlR0RWT","outputId":"544d0c4b-5267-4fc3-f67c-55b4f29f5d37"},"outputs":[],"source":["# model.to('cpu')\n","mb1.eval()\n","\n","def outputs_doc(model, test_loader):\n","    print(\"Getting model outputs...\")\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    model.eval()\n","\n","    all_outputs = []\n","\n","    with torch.no_grad():\n","        for ref_inputs, _ in test_loader:\n","            ref_inputs = ref_inputs.to(device)\n","            ref_outputs = model(ref_inputs)\n","            all_outputs.append(ref_outputs.cpu())\n","\n","    return all_outputs[0]\n","\n","legitimate_dataset = DOCDataset(legitimate, transform=transform)\n","legitimate_loader = DataLoader(legitimate_dataset, batch_size=len(legitimate_dataset), shuffle=False)\n","legitimate_outputs = outputs_doc(mb1, legitimate_loader)\n","print(\"legitimate outputs:\",len(legitimate_outputs))\n","# augmented_legitimate_loader = DataLoader(target_dataset, batch_size=len(target_dataset), shuffle=False)\n","# augmented_legitimate_outputs = outputs_doc(mb2, augmented_legitimate_loader)\n","# print(\"augmented legitimate outputs:\",len(augmented_legitimate_outputs))\n","reconstructed_attack_dataset = DOCDataset(reconstructed_attack, transform=transform)\n","reconstructed_attack_loader = DataLoader(reconstructed_attack_dataset, batch_size=len(reconstructed_attack_dataset), shuffle=False)\n","reconstructed_attack_outputs = outputs_doc(mb1, reconstructed_attack_loader)\n","print(\"Reconstructed attack outputs:\",len(reconstructed_attack_outputs))\n","attack1_dataset = DOCDataset(attack1, transform=transform)\n","attack1_loader = DataLoader(attack1_dataset, batch_size=len(attack1_dataset), shuffle=False)\n","attack1_outputs = outputs_doc(mb1, attack1_loader)\n","print(\"HackRF One (1) outputs:\",len(attack1_outputs))\n","attack2_dataset = DOCDataset(attack2, transform=transform)\n","attack2_loader = DataLoader(attack2_dataset, batch_size=len(attack2_dataset), shuffle=False)\n","attack2_outputs = outputs_doc(mb1, attack2_loader)\n","print(\"HackRF One (2) outputs:\",len(attack2_outputs))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["attack2_outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":465,"status":"ok","timestamp":1731624435625,"user":{"displayName":"Aryan Nath","userId":"00381514932192010045"},"user_tz":-330},"id":"x6FpxBW40RWU","outputId":"14f594f1-166b-4306-8dff-743f82efe93e"},"outputs":[],"source":["print(legitimate_outputs[0],len(legitimate_outputs[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1731624436281,"user":{"displayName":"Aryan Nath","userId":"00381514932192010045"},"user_tz":-330},"id":"k-6Yl7dP0RWV","outputId":"40f8cd1f-2ca6-45d5-a3a5-d1208bacc28c"},"outputs":[],"source":["attack1_outputs.shape"]},{"cell_type":"markdown","metadata":{"id":"QHCdaHtx0RWW"},"source":["## FFT Dataset"]},{"cell_type":"markdown","metadata":{"id":"cwbzUEgb0RWb"},"source":["Results with aug_legitimate = 200, reconstructed_attack = 200"]},{"cell_type":"markdown","metadata":{"id":"WxEGjm0xl4vQ"},"source":["### MobileNetV2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":755,"status":"ok","timestamp":1731251201798,"user":{"displayName":"Aryan Nath","userId":"02241134929809287163"},"user_tz":-330},"id":"Gu5ykzhK0RWc","outputId":"4e3ff93b-1150-4ad6-e0e0-b2e11ff53d01"},"outputs":[],"source":["# One class SVM\n","import numpy as np\n","from sklearn import svm\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import classification_report\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","scaler = StandardScaler()\n","\n","def train_svm_and_get_scores(X_train, X_test):\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","    clf = svm.OneClassSVM(kernel='rbf',nu=0.1)\n","    clf.fit(X_train)\n","    scores = clf.decision_function(X_test)\n","    return scores\n","\n","X_train, X_test = train_test_split(augmented_legitimate_outputs, test_size=0.3, random_state=42)\n","\n","aug_legitimate_scores = train_svm_and_get_scores(X_train, X_test)\n","\n","mu = np.mean(aug_legitimate_scores)\n","sigma = np.std(aug_legitimate_scores)\n","\n","legitimate_scores = train_svm_and_get_scores(X_train, legitimate_outputs)\n","\n","legitimate_scores_norm = np.abs((legitimate_scores - mu) / sigma)\n","\n","thresholdsvm = np.percentile(legitimate_scores_norm, 95)\n","legitimate_predictions = (legitimate_scores_norm > thresholdsvm).astype(int)\n","\n","def evaluate_attack_outputs(attack_outputs, device_name):\n","    scores = train_svm_and_get_scores(X_train, attack_outputs)\n","    scores_norm = np.abs((scores - mu) / sigma)\n","    predictions = (scores_norm > thresholdsvm).astype(int)\n","    y_test = np.ones(len(attack_outputs))  # True labels for attack outputs\n","    return scores_norm, predictions, y_test\n","\n","hackrf1_scores, svmhackrf1_pred, hackrf1_true = evaluate_attack_outputs(attack1_outputs, 'HackRF1')\n","hackrf2_scores, svmhackrf2_pred, hackrf2_true = evaluate_attack_outputs(attack2_outputs, 'HackRF2')\n","\n","combined_predictions = np.concatenate([legitimate_predictions,svmhackrf1_pred, svmhackrf2_pred])\n","true_labels = np.concatenate([np.zeros_like(legitimate_predictions), hackrf1_true, hackrf2_true])\n","\n","plot_data = [\n","    legitimate_scores_norm,\n","    hackrf1_scores,\n","    hackrf2_scores\n","]\n","\n","plt.figure(figsize=(8, 10))\n","colors = sns.color_palette(\"Set1\", n_colors=3)\n","\n","sns.boxplot(data=plot_data, width=0.3, palette=colors, linewidth=2.5)\n","plt.axhline(y=thresholdsvm, color='g', linestyle='--', linewidth=2, label='Threshold')\n","plt.xticks([0, 1, 2], ['Legitimate Device', 'HackRF#1', 'HackRF#2'], fontsize=14)\n","plt.yticks(fontsize=14)\n","plt.ylabel('Normalized Score', fontsize=16)\n","plt.title('SVM', fontsize=18)\n","plt.legend(fontsize=14)\n","plt.grid(True, linestyle='--', linewidth=1)\n","plt.show()\n","\n","print(\"Classification Report for SVM\")\n","print(classification_report(true_labels, combined_predictions, target_names=['Legitimate', 'Attack']))\n","\n","cm = confusion_matrix(true_labels, combined_predictions)\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Legitimate', 'Attack'], yticklabels=['Legitimate', 'Attack'])\n","\n","\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","clf = svm.OneClassSVM(kernel='rbf',nu=0.1)\n","clf.fit(X_train)\n","scores = clf.decision_function(X_test)"]},{"cell_type":"markdown","metadata":{"id":"pq_I1vKH0RWe"},"source":["Dataset type: fft\n","Loading datasets...\n","dataset size: 398 200\n","Epoch [1/150], Distillation Loss: 83.9222, Compactness Loss: 0.3000\n","Epoch [2/150], Distillation Loss: 55.2911, Compactness Loss: 0.3357\n","Epoch [3/150], Distillation Loss: 34.3194, Compactness Loss: 0.4186\n","Epoch [4/150], Distillation Loss: 21.9955, Compactness Loss: 0.4969\n","Epoch [5/150], Distillation Loss: 12.4640, Compactness Loss: 0.3951\n","Epoch [6/150], Distillation Loss: 7.8847, Compactness Loss: 0.2830\n","Epoch [7/150], Distillation Loss: 5.4785, Compactness Loss: 0.2347\n","Epoch [8/150], Distillation Loss: 4.5340, Compactness Loss: 0.2170\n","Epoch [9/150], Distillation Loss: 3.8690, Compactness Loss: 0.2165\n","Epoch [10/150], Distillation Loss: 3.8661, Compactness Loss: 0.2138\n","Epoch [11/150], Distillation Loss: 4.6998, Compactness Loss: 0.2275\n","Epoch [12/150], Distillation Loss: 1.4533, Compactness Loss: 0.2026\n","Epoch [13/150], Distillation Loss: 3.2722, Compactness Loss: 0.2008\n","Epoch [14/150], Distillation Loss: 2.2604, Compactness Loss: 0.2095\n","Epoch [15/150], Distillation Loss: 2.8327, Compactness Loss: 0.2681\n","Epoch [16/150], Distillation Loss: 1.8807, Compactness Loss: 0.2034\n","Epoch [17/150], Distillation Loss: 1.0705, Compactness Loss: 0.2075\n","Epoch [18/150], Distillation Loss: 2.3981, Compactness Loss: 0.2110\n","Epoch [19/150], Distillation Loss: 1.2390, Compactness Loss: 0.1976\n","Epoch [20/150], Distillation Loss: 1.5615, Compactness Loss: 0.2107\n","Epoch [21/150], Distillation Loss: 2.2426, Compactness Loss: 0.1987\n","Epoch [22/150], Distillation Loss: 1.8382, Compactness Loss: 0.2060\n","Epoch [23/150], Distillation Loss: 1.3549, Compactness Loss: 0.1984\n","Epoch [24/150], Distillation Loss: 0.9903, Compactness Loss: 0.1879\n","Epoch [25/150], Distillation Loss: 1.1162, Compactness Loss: 0.2010\n","Epoch [26/150], Distillation Loss: 0.6727, Compactness Loss: 0.1919\n","Epoch [27/150], Distillation Loss: 0.5745, Compactness Loss: 0.1900\n","Epoch [28/150], Distillation Loss: 0.8350, Compactness Loss: 0.1867\n","Epoch [29/150], Distillation Loss: 0.5002, Compactness Loss: 0.1868\n","Epoch [30/150], Distillation Loss: 1.0260, Compactness Loss: 0.1799\n","Epoch [31/150], Distillation Loss: 0.5230, Compactness Loss: 0.1809\n","Epoch [32/150], Distillation Loss: 0.6414, Compactness Loss: 0.1815\n","Epoch [33/150], Distillation Loss: 0.3791, Compactness Loss: 0.1791\n","Epoch [34/150], Distillation Loss: 0.4855, Compactness Loss: 0.1774\n","Epoch [35/150], Distillation Loss: 0.6883, Compactness Loss: 0.1768\n","Epoch [36/150], Distillation Loss: 0.4035, Compactness Loss: 0.1769\n","Epoch [37/150], Distillation Loss: 0.4856, Compactness Loss: 0.1726\n","Epoch [38/150], Distillation Loss: 0.5027, Compactness Loss: 0.1704\n","Epoch [39/150], Distillation Loss: 0.3690, Compactness Loss: 0.1717\n","Epoch [40/150], Distillation Loss: 0.5338, Compactness Loss: 0.1743\n","Epoch [41/150], Distillation Loss: 0.3590, Compactness Loss: 0.1690\n","Epoch [42/150], Distillation Loss: 0.3697, Compactness Loss: 0.1657\n","Epoch [43/150], Distillation Loss: 0.3189, Compactness Loss: 0.1649\n","Epoch [44/150], Distillation Loss: 0.7049, Compactness Loss: 0.1653\n","Epoch [45/150], Distillation Loss: 1.6643, Compactness Loss: 0.1665\n","Epoch [46/150], Distillation Loss: 0.4096, Compactness Loss: 0.1712\n","Epoch [47/150], Distillation Loss: 0.4575, Compactness Loss: 0.1682\n","Epoch [48/150], Distillation Loss: 0.3637, Compactness Loss: 0.1678\n","Epoch [49/150], Distillation Loss: 0.9134, Compactness Loss: 0.1668\n","Epoch [50/150], Distillation Loss: 0.3517, Compactness Loss: 0.1643\n","Epoch [51/150], Distillation Loss: 0.3483, Compactness Loss: 0.1620\n","Epoch [52/150], Distillation Loss: 0.3420, Compactness Loss: 0.1604\n","Epoch [53/150], Distillation Loss: 0.3487, Compactness Loss: 0.1597\n","Epoch [54/150], Distillation Loss: 0.6052, Compactness Loss: 0.1597\n","Epoch [55/150], Distillation Loss: 0.4842, Compactness Loss: 0.1617\n","Epoch [56/150], Distillation Loss: 0.3242, Compactness Loss: 0.1586\n","Epoch [57/150], Distillation Loss: 0.3588, Compactness Loss: 0.1554\n","Epoch [58/150], Distillation Loss: 0.3693, Compactness Loss: 0.1537\n","Epoch [59/150], Distillation Loss: 0.5997, Compactness Loss: 0.1501\n","Epoch [60/150], Distillation Loss: 0.3100, Compactness Loss: 0.1569\n","Epoch [61/150], Distillation Loss: 0.4719, Compactness Loss: 0.1536\n","Epoch [62/150], Distillation Loss: 0.3140, Compactness Loss: 0.1535\n","Epoch [63/150], Distillation Loss: 0.5892, Compactness Loss: 0.1511\n","Epoch [64/150], Distillation Loss: 0.3174, Compactness Loss: 0.1500\n","Epoch [65/150], Distillation Loss: 0.3492, Compactness Loss: 0.1511\n","Epoch [66/150], Distillation Loss: 0.2995, Compactness Loss: 0.1469\n","Epoch [67/150], Distillation Loss: 0.3313, Compactness Loss: 0.1491\n","Epoch [68/150], Distillation Loss: 0.3446, Compactness Loss: 0.1481\n","Epoch [69/150], Distillation Loss: 0.5312, Compactness Loss: 0.1437\n","Epoch [70/150], Distillation Loss: 0.2980, Compactness Loss: 0.1430\n","Epoch [71/150], Distillation Loss: 0.3233, Compactness Loss: 0.1441\n","Epoch [72/150], Distillation Loss: 0.3786, Compactness Loss: 0.1389\n","Epoch [73/150], Distillation Loss: 0.5249, Compactness Loss: 0.1432\n","Epoch [74/150], Distillation Loss: 0.5553, Compactness Loss: 0.1389\n","Epoch [75/150], Distillation Loss: 0.3617, Compactness Loss: 0.1432\n","Epoch [76/150], Distillation Loss: 0.2776, Compactness Loss: 0.1409\n","Epoch [77/150], Distillation Loss: 0.3547, Compactness Loss: 0.1406\n","Epoch [78/150], Distillation Loss: 0.3515, Compactness Loss: 0.1394\n","Epoch [79/150], Distillation Loss: 0.2976, Compactness Loss: 0.1375\n","Epoch [80/150], Distillation Loss: 0.2848, Compactness Loss: 0.1377\n","Epoch [81/150], Distillation Loss: 0.3381, Compactness Loss: 0.1382\n","Epoch [82/150], Distillation Loss: 0.3213, Compactness Loss: 0.1325\n","Epoch [83/150], Distillation Loss: 0.4132, Compactness Loss: 0.1345\n","Epoch [84/150], Distillation Loss: 0.6448, Compactness Loss: 0.1343\n","Epoch [85/150], Distillation Loss: 0.2867, Compactness Loss: 0.1372\n","Epoch [86/150], Distillation Loss: 0.2905, Compactness Loss: 0.1326\n","Epoch [87/150], Distillation Loss: 0.2862, Compactness Loss: 0.1311\n","Epoch [88/150], Distillation Loss: 0.3204, Compactness Loss: 0.1323\n","Epoch [89/150], Distillation Loss: 0.2998, Compactness Loss: 0.1315\n","Epoch [90/150], Distillation Loss: 0.2783, Compactness Loss: 0.1274\n","Epoch [91/150], Distillation Loss: 0.2818, Compactness Loss: 0.1306\n","Epoch [92/150], Distillation Loss: 0.3202, Compactness Loss: 0.1245\n","Epoch [93/150], Distillation Loss: 0.2894, Compactness Loss: 0.1240\n","Epoch [94/150], Distillation Loss: 0.2786, Compactness Loss: 0.1238\n","Epoch [95/150], Distillation Loss: 0.2618, Compactness Loss: 0.1227\n","Epoch [96/150], Distillation Loss: 0.2599, Compactness Loss: 0.1245\n","Epoch [97/150], Distillation Loss: 0.2687, Compactness Loss: 0.1226\n","Epoch [98/150], Distillation Loss: 0.2945, Compactness Loss: 0.1219\n","Epoch [99/150], Distillation Loss: 0.2643, Compactness Loss: 0.1213\n","Epoch [100/150], Distillation Loss: 0.3117, Compactness Loss: 0.1194\n","Epoch [101/150], Distillation Loss: 0.2946, Compactness Loss: 0.1211\n","Epoch [102/150], Distillation Loss: 0.2692, Compactness Loss: 0.1204\n","Epoch [103/150], Distillation Loss: 0.2916, Compactness Loss: 0.1180\n","Epoch [104/150], Distillation Loss: 0.3014, Compactness Loss: 0.1180\n","Epoch [105/150], Distillation Loss: 0.2786, Compactness Loss: 0.1185\n","Epoch [106/150], Distillation Loss: 0.2669, Compactness Loss: 0.1168\n","Epoch [107/150], Distillation Loss: 0.5297, Compactness Loss: 0.1151\n","Epoch [108/150], Distillation Loss: 0.2664, Compactness Loss: 0.1159\n","Epoch [109/150], Distillation Loss: 0.2930, Compactness Loss: 0.1162\n","Epoch [110/150], Distillation Loss: 0.3622, Compactness Loss: 0.1150\n","Epoch [111/150], Distillation Loss: 0.4320, Compactness Loss: 0.1125\n","Epoch [112/150], Distillation Loss: 0.3041, Compactness Loss: 0.1123\n","Epoch [113/150], Distillation Loss: 0.4441, Compactness Loss: 0.1136\n","Epoch [114/150], Distillation Loss: 0.2997, Compactness Loss: 0.1183\n","Epoch [115/150], Distillation Loss: 0.2738, Compactness Loss: 0.1141\n","Epoch [116/150], Distillation Loss: 0.3144, Compactness Loss: 0.1139\n","Epoch [117/150], Distillation Loss: 0.3102, Compactness Loss: 0.1150\n","Epoch [118/150], Distillation Loss: 0.3027, Compactness Loss: 0.1116\n","Epoch [119/150], Distillation Loss: 0.2598, Compactness Loss: 0.1161\n","Epoch [120/150], Distillation Loss: 0.3247, Compactness Loss: 0.1100\n","Epoch [121/150], Distillation Loss: 0.2923, Compactness Loss: 0.1106\n","Epoch [122/150], Distillation Loss: 0.2850, Compactness Loss: 0.1112\n","Epoch [123/150], Distillation Loss: 0.2784, Compactness Loss: 0.1067\n","Epoch [124/150], Distillation Loss: 0.2364, Compactness Loss: 0.1091\n","Epoch [125/150], Distillation Loss: 0.2705, Compactness Loss: 0.1076\n","Epoch [126/150], Distillation Loss: 0.2515, Compactness Loss: 0.1054\n","Epoch [127/150], Distillation Loss: 0.2643, Compactness Loss: 0.1057\n","Epoch [128/150], Distillation Loss: 0.2678, Compactness Loss: 0.1091\n","Epoch [129/150], Distillation Loss: 0.2851, Compactness Loss: 0.1034\n","Epoch [130/150], Distillation Loss: 0.2323, Compactness Loss: 0.1060\n","Epoch [131/150], Distillation Loss: 0.2642, Compactness Loss: 0.1016\n","Epoch [132/150], Distillation Loss: 0.3153, Compactness Loss: 0.1043\n","Epoch [133/150], Distillation Loss: 0.2771, Compactness Loss: 0.1004\n","Epoch [134/150], Distillation Loss: 0.2793, Compactness Loss: 0.1021\n","Epoch [135/150], Distillation Loss: 0.2968, Compactness Loss: 0.0995\n","Epoch [136/150], Distillation Loss: 0.2413, Compactness Loss: 0.0987\n","Epoch [137/150], Distillation Loss: 0.2552, Compactness Loss: 0.0972\n","Epoch [138/150], Distillation Loss: 0.2427, Compactness Loss: 0.0978\n","Epoch [139/150], Distillation Loss: 0.2576, Compactness Loss: 0.0965\n","Epoch [140/150], Distillation Loss: 0.2431, Compactness Loss: 0.0974\n","Epoch [141/150], Distillation Loss: 0.2438, Compactness Loss: 0.0980\n","Epoch [142/150], Distillation Loss: 0.2429, Compactness Loss: 0.0977\n","Epoch [143/150], Distillation Loss: 0.2602, Compactness Loss: 0.0946\n","Epoch [144/150], Distillation Loss: 0.2611, Compactness Loss: 0.0949\n","Epoch [145/150], Distillation Loss: 0.2487, Compactness Loss: 0.0938\n","Epoch [146/150], Distillation Loss: 0.2434, Compactness Loss: 0.0943\n","Epoch [147/150], Distillation Loss: 0.2822, Compactness Loss: 0.0941\n","Epoch [148/150], Distillation Loss: 0.3097, Compactness Loss: 0.0947\n","Epoch [149/150], Distillation Loss: 0.2473, Compactness Loss: 0.0961\n","Epoch [150/150], Distillation Loss: 0.2596, Compactness Loss: 0.0916\n","training runtime: 722.0822813510895"]},{"cell_type":"markdown","metadata":{"id":"Cbhk5yaJJS0q"},"source":["### MobileNetV1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2553,"status":"ok","timestamp":1731444665538,"user":{"displayName":"Aryan Nath","userId":"02241134929809287163"},"user_tz":-330},"id":"fLIkzDmUJNew","outputId":"bf4dd12c-7810-40e1-ab69-44346d2e251f"},"outputs":[],"source":["# One class SVM\n","import numpy as np\n","from sklearn import svm\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import classification_report\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","scaler = StandardScaler()\n","\n","def train_svm_and_get_scores(X_train, X_test):\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","    clf = svm.OneClassSVM(kernel='rbf',nu=0.1)\n","    clf.fit(X_train)\n","    scores = clf.decision_function(X_test)\n","    return scores\n","\n","X_train, X_test = train_test_split(augmented_legitimate_outputs, test_size=0.3, random_state=42)\n","\n","aug_legitimate_scores = train_svm_and_get_scores(X_train, X_test)\n","\n","mu = np.mean(aug_legitimate_scores)\n","sigma = np.std(aug_legitimate_scores)\n","\n","legitimate_scores = train_svm_and_get_scores(X_train, legitimate_outputs)\n","\n","legitimate_scores_norm = np.abs((legitimate_scores - mu) / sigma)\n","\n","thresholdsvm = np.percentile(legitimate_scores_norm, 95)\n","legitimate_predictions = (legitimate_scores_norm > thresholdsvm).astype(int)\n","\n","def evaluate_attack_outputs(attack_outputs, device_name):\n","    scores = train_svm_and_get_scores(X_train, attack_outputs)\n","    scores_norm = np.abs((scores - mu) / sigma)\n","    predictions = (scores_norm > thresholdsvm).astype(int)\n","    y_test = np.ones(len(attack_outputs))  # True labels for attack outputs\n","    return scores_norm, predictions, y_test\n","\n","hackrf1_scores, svmhackrf1_pred, hackrf1_true = evaluate_attack_outputs(attack1_outputs, 'HackRF1')\n","hackrf2_scores, svmhackrf2_pred, hackrf2_true = evaluate_attack_outputs(attack2_outputs, 'HackRF2')\n","\n","combined_predictions = np.concatenate([legitimate_predictions,svmhackrf1_pred, svmhackrf2_pred])\n","true_labels = np.concatenate([np.zeros_like(legitimate_predictions), hackrf1_true, hackrf2_true])\n","\n","plot_data = [\n","    legitimate_scores_norm,\n","    hackrf1_scores,\n","    hackrf2_scores\n","]\n","\n","plt.figure(figsize=(8, 10))\n","colors = sns.color_palette(\"Set1\", n_colors=3)\n","\n","sns.boxplot(data=plot_data, width=0.3, palette=colors, linewidth=2.5)\n","plt.axhline(y=thresholdsvm, color='g', linestyle='--', linewidth=2, label='Threshold')\n","plt.xticks([0, 1, 2], ['Legitimate Device', 'HackRF#1', 'HackRF#2'], fontsize=14)\n","plt.yticks(fontsize=14)\n","plt.ylabel('Normalized Score', fontsize=16)\n","plt.title('SVM', fontsize=18)\n","plt.legend(fontsize=14)\n","plt.grid(True, linestyle='--', linewidth=1)\n","plt.show()\n","\n","print(\"Classification Report for SVM\")\n","print(classification_report(true_labels, combined_predictions, target_names=['Legitimate', 'Attack']))\n","\n","cm = confusion_matrix(true_labels, combined_predictions)\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Legitimate', 'Attack'], yticklabels=['Legitimate', 'Attack'])\n","\n","\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","clf = svm.OneClassSVM(kernel='rbf',nu=0.1)\n","clf.fit(X_train)\n","scores = clf.decision_function(X_test)"]},{"cell_type":"markdown","metadata":{"id":"7DHm2ObmaNne"},"source":["## FFT Dataset"]},{"cell_type":"markdown","metadata":{"id":"xbz8YTf0aPjv"},"source":["Result with aug_legitimate = 700, reconstructed_attack = 700"]},{"cell_type":"markdown","metadata":{"id":"zL31qJ9_aeYl"},"source":["### MobileNetV1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2556,"status":"ok","timestamp":1731616937675,"user":{"displayName":"Aryan Nath","userId":"00381514932192010045"},"user_tz":-330},"id":"AT-HYtM7aVMP","outputId":"bed73887-7554-420f-b64c-0b0a8758bf5a"},"outputs":[],"source":["# One class SVM\n","import numpy as np\n","from sklearn import svm\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import classification_report\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","scaler = StandardScaler()\n","\n","def train_svm_and_get_scores(X_train, X_test):\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","    clf = svm.OneClassSVM(kernel='rbf',nu=0.1)\n","    clf.fit(X_train)\n","    scores = clf.decision_function(X_test)\n","    return scores\n","\n","X_train, X_test = train_test_split(augmented_legitimate_outputs, test_size=0.3, random_state=42)\n","\n","aug_legitimate_scores = train_svm_and_get_scores(X_train, X_test)\n","\n","mu = np.mean(aug_legitimate_scores)\n","sigma = np.std(aug_legitimate_scores)\n","\n","legitimate_scores = train_svm_and_get_scores(X_train, legitimate_outputs)\n","\n","legitimate_scores_norm = np.abs((legitimate_scores - mu) / sigma)\n","\n","thresholdsvm = np.percentile(legitimate_scores_norm, 95)\n","legitimate_predictions = (legitimate_scores_norm > thresholdsvm).astype(int)\n","\n","def evaluate_attack_outputs(attack_outputs, device_name):\n","    scores = train_svm_and_get_scores(X_train, attack_outputs)\n","    scores_norm = np.abs((scores - mu) / sigma)\n","    predictions = (scores_norm > thresholdsvm).astype(int)\n","    y_test = np.ones(len(attack_outputs))  # True labels for attack outputs\n","    return scores_norm, predictions, y_test\n","\n","hackrf1_scores, svmhackrf1_pred, hackrf1_true = evaluate_attack_outputs(attack1_outputs, 'HackRF1')\n","hackrf2_scores, svmhackrf2_pred, hackrf2_true = evaluate_attack_outputs(attack2_outputs, 'HackRF2')\n","\n","combined_predictions = np.concatenate([legitimate_predictions,svmhackrf1_pred, svmhackrf2_pred])\n","true_labels = np.concatenate([np.zeros_like(legitimate_predictions), hackrf1_true, hackrf2_true])\n","\n","plot_data = [\n","    legitimate_scores_norm,\n","    hackrf1_scores,\n","    hackrf2_scores\n","]\n","\n","plt.figure(figsize=(8, 10))\n","colors = sns.color_palette(\"Set1\", n_colors=3)\n","\n","sns.boxplot(data=plot_data, width=0.3, palette=colors, linewidth=2.5)\n","plt.axhline(y=thresholdsvm, color='g', linestyle='--', linewidth=2, label='Threshold')\n","plt.xticks([0, 1, 2], ['Legitimate Device', 'HackRF#1', 'HackRF#2'], fontsize=14)\n","plt.yticks(fontsize=14)\n","plt.ylabel('Normalized Score', fontsize=16)\n","plt.title('SVM', fontsize=18)\n","plt.legend(fontsize=14)\n","plt.grid(True, linestyle='--', linewidth=1)\n","plt.show()\n","\n","print(\"Classification Report for SVM\")\n","print(classification_report(true_labels, combined_predictions, target_names=['Legitimate', 'Attack']))\n","\n","cm = confusion_matrix(true_labels, combined_predictions)\n","sns.heatmap(cm, annot=True, fmt='d', xticklabels=['Legitimate', 'Attack'], yticklabels=['Legitimate', 'Attack'])\n","\n","\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","clf = svm.OneClassSVM(kernel='rbf',nu=0.1)\n","clf.fit(X_train)\n","scores = clf.decision_function(X_test)"]},{"cell_type":"markdown","metadata":{"id":"nanrSzsm3E48"},"source":["### MobileNetV2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2958,"status":"ok","timestamp":1731624469406,"user":{"displayName":"Aryan Nath","userId":"00381514932192010045"},"user_tz":-330},"id":"SdvMvdF23Gey","outputId":"fa6c7932-ef2a-4cdf-d9fe-380dac9af252"},"outputs":[],"source":["# One class SVM\n","import numpy as np\n","from sklearn import svm\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import classification_report\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","scaler = StandardScaler()\n","\n","def train_svm_and_get_scores(X_train, X_test):\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","    clf = svm.OneClassSVM(kernel='rbf',nu=0.1)\n","    clf.fit(X_train)\n","    scores = clf.decision_function(X_test)\n","    return scores\n","\n","X_train, X_test = train_test_split(augmented_legitimate_outputs, test_size=0.3, random_state=42)\n","\n","aug_legitimate_scores = train_svm_and_get_scores(X_train, X_test)\n","\n","mu = np.mean(aug_legitimate_scores)\n","sigma = np.std(aug_legitimate_scores)\n","\n","legitimate_scores = train_svm_and_get_scores(X_train, legitimate_outputs)\n","\n","legitimate_scores_norm = np.abs((legitimate_scores - mu) / sigma)\n","\n","thresholdsvm = np.percentile(legitimate_scores_norm, 95)\n","legitimate_predictions = (legitimate_scores_norm > thresholdsvm).astype(int)\n","\n","def evaluate_attack_outputs(attack_outputs, device_name):\n","    scores = train_svm_and_get_scores(X_train, attack_outputs)\n","    scores_norm = np.abs((scores - mu) / sigma)\n","    predictions = (scores_norm > thresholdsvm).astype(int)\n","    y_test = np.ones(len(attack_outputs))  # True labels for attack outputs\n","    return scores_norm, predictions, y_test\n","\n","hackrf1_scores, svmhackrf1_pred, hackrf1_true = evaluate_attack_outputs(attack1_outputs, 'HackRF1')\n","hackrf2_scores, svmhackrf2_pred, hackrf2_true = evaluate_attack_outputs(attack2_outputs, 'HackRF2')\n","\n","combined_predictions = np.concatenate([legitimate_predictions,svmhackrf1_pred, svmhackrf2_pred])\n","true_labels = np.concatenate([np.zeros_like(legitimate_predictions), hackrf1_true, hackrf2_true])\n","\n","plot_data = [\n","    legitimate_scores_norm,\n","    hackrf1_scores,\n","    hackrf2_scores\n","]\n","\n","plt.figure(figsize=(8, 10))\n","colors = sns.color_palette(\"Set1\", n_colors=3)\n","\n","sns.boxplot(data=plot_data, width=0.3, palette=colors, linewidth=2.5)\n","plt.axhline(y=thresholdsvm, color='g', linestyle='--', linewidth=2, label='Threshold')\n","plt.xticks([0, 1, 2], ['Legitimate Device', 'HackRF#1', 'HackRF#2'], fontsize=14)\n","plt.yticks(fontsize=14)\n","plt.ylabel('Normalized Score', fontsize=16)\n","plt.title('SVM', fontsize=18)\n","plt.legend(fontsize=14)\n","plt.grid(True, linestyle='--', linewidth=1)\n","plt.show()\n","\n","print(\"Classification Report for SVM\")\n","print(classification_report(true_labels, combined_predictions, target_names=['Legitimate', 'Attack']))\n","\n","cm = confusion_matrix(true_labels, combined_predictions)\n","sns.heatmap(cm, annot=True, fmt='d', xticklabels=['Legitimate', 'Attack'], yticklabels=['Legitimate', 'Attack'])\n","\n","\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","clf = svm.OneClassSVM(kernel='rbf',nu=0.1)\n","clf.fit(X_train)\n","scores = clf.decision_function(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# One class SVM\n","import numpy as np\n","from sklearn import svm\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import classification_report\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","scaler = StandardScaler()\n","\n","def train_svm_and_get_scores(X_train, X_test):\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","    clf = svm.OneClassSVM(kernel='rbf',nu=0.1)\n","    clf.fit(X_train)\n","    scores = clf.decision_function(X_test)\n","    return scores\n","\n","X_train, X_test = train_test_split(augmented_legitimate_outputs, test_size=0.3, random_state=42)\n","\n","aug_legitimate_scores = train_svm_and_get_scores(X_train, X_test)\n","\n","mu = np.mean(aug_legitimate_scores)\n","sigma = np.std(aug_legitimate_scores)\n","\n","legitimate_scores = train_svm_and_get_scores(X_train, legitimate_outputs)\n","\n","legitimate_scores_norm = np.abs((legitimate_scores - mu) / sigma)\n","\n","thresholdsvm = np.percentile(legitimate_scores_norm, 95)\n","legitimate_predictions = (legitimate_scores_norm > thresholdsvm).astype(int)\n","\n","def evaluate_attack_outputs(attack_outputs, device_name):\n","    scores = train_svm_and_get_scores(X_train, attack_outputs)\n","    scores_norm = np.abs((scores - mu) / sigma)\n","    predictions = (scores_norm > thresholdsvm).astype(int)\n","    y_test = np.ones(len(attack_outputs))  # True labels for attack outputs\n","    return scores_norm, predictions, y_test\n","\n","hackrf1_scores, svmhackrf1_pred, hackrf1_true = evaluate_attack_outputs(attack1_outputs, 'HackRF1')\n","hackrf2_scores, svmhackrf2_pred, hackrf2_true = evaluate_attack_outputs(attack2_outputs, 'HackRF2')\n","\n","combined_predictions = np.concatenate([legitimate_predictions,svmhackrf1_pred, svmhackrf2_pred])\n","true_labels = np.concatenate([np.zeros_like(legitimate_predictions), hackrf1_true, hackrf2_true])\n","\n","plot_data = [\n","    legitimate_scores_norm,\n","    hackrf1_scores,\n","    hackrf2_scores\n","]\n","\n","plt.figure(figsize=(8, 10))\n","colors = sns.color_palette(\"Set1\", n_colors=3)\n","sns.set(style=\"whitegrid\")\n","plt.figure(figsize=(6, 6))\n","sns.boxplot(data=plot_data, width=0.3, palette=colors, linewidth=1.5, boxprops=dict(alpha=0.5))\n","plt.axhline(y=thresholdsvm, color='green', linestyle='--', linewidth=2, label='decision boundary')\n","plt.xticks([0, 1, 2], ['Legitimate', 'HackRF #1', 'HackRF #2'], fontsize=12)\n","plt.yticks(fontsize=12)\n","plt.ylabel('Normalized Distance', fontsize=14)\n","plt.xlabel('')\n","plt.title('k-NN', fontsize=14)\n","plt.legend(fontsize=12, loc='best')\n","plt.grid(True, linestyle='--', linewidth=0.5)\n","plt.minorticks_on()\n","plt.show()\n","\n","print(\"Classification Report for SVM\")\n","print(classification_report(true_labels, combined_predictions, target_names=['Legitimate', 'Attack']))\n","\n","cm = confusion_matrix(true_labels, combined_predictions)\n","sns.heatmap(cm, annot=True, fmt='d', xticklabels=['Legitimate', 'Attack'], yticklabels=['Legitimate', 'Attack'])\n","\n","\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","clf = svm.OneClassSVM(kernel='rbf',nu=0.1)\n","clf.fit(X_train)\n","scores = clf.decision_function(X_test)"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"executionInfo":{"elapsed":1644,"status":"error","timestamp":1731624652573,"user":{"displayName":"Aryan Nath","userId":"00381514932192010045"},"user_tz":-330},"id":"slZxLyda3tTc","outputId":"b436a3b7-e422-47b0-929b-deb1f100a9b8"},"outputs":[],"source":["# with open('svm_mobilenetv2_fft_aug.pkl','wb') as f:\n","#     pickle.dump(clf,f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MwEv-moh5A5A"},"outputs":[],"source":["import pickle\n","\n","model.to('cpu')\n","\n","model.eval()\n","\n","# with open('mobilenetv2_fft.pkl','wb') as f:\n","#   pickle.dump(model,f)\n","\n","traced_model = torch.jit.script(model)\n","\n","# Save the scripted model\n","traced_model.save(\"mobilenetv2_fft.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RWPfyHiJqIAt"},"outputs":[],"source":["import torch\n","\n","# Load the model on CPU\n","model = torch.jit.load(\"resnet_fft.pt\", map_location=torch.device('cpu'))\n","\n","# If loading on GPU (if available), specify `cuda`\n","# model = torch.jit.load(\"resnet_fft.pt\", map_location=torch.device('cuda'))\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1731251957479,"user":{"displayName":"Aryan Nath","userId":"02241134929809287163"},"user_tz":-330},"id":"-5Ayh8M05O2D","outputId":"dd6718fa-d0cd-4ed0-997c-256859b08178"},"outputs":[],"source":["!ls"]},{"cell_type":"markdown","metadata":{"id":"Of9aj9rT0RWf"},"source":["### IQ Data Constellation Dataset"]},{"cell_type":"markdown","metadata":{"id":"zO7YL9Il0RWg"},"source":["Results without any proprocessing of the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"75ZYFsDJ0RWg","outputId":"bb364838-d5a2-4785-9dd3-ef667410b51c"},"outputs":[],"source":["# One class SVM\n","import numpy as np\n","from sklearn import svm\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import classification_report\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","scaler = StandardScaler()\n","\n","def train_svm_and_get_scores(X_train, X_test):\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","    clf = svm.OneClassSVM(kernel='rbf',nu=0.1)\n","    clf.fit(X_train)\n","    scores = clf.decision_function(X_test)\n","    return scores\n","\n","X_train, X_test = train_test_split(augmented_legitimate_outputs, test_size=0.3, random_state=42)\n","\n","aug_legitimate_scores = train_svm_and_get_scores(X_train, X_test)\n","\n","mu = np.mean(aug_legitimate_scores)\n","sigma = np.std(aug_legitimate_scores)\n","\n","legitimate_scores = train_svm_and_get_scores(X_train, legitimate_outputs)\n","\n","legitimate_scores_norm = np.abs((legitimate_scores - mu) / sigma)\n","\n","thresholdsvm = np.percentile(legitimate_scores_norm, 95)\n","legitimate_predictions = (legitimate_scores_norm > thresholdsvm).astype(int)\n","\n","def evaluate_attack_outputs(attack_outputs, device_name):\n","    scores = train_svm_and_get_scores(X_train, attack_outputs)\n","    scores_norm = np.abs((scores - mu) / sigma)\n","    predictions = (scores_norm > thresholdsvm).astype(int)\n","    y_test = np.ones(len(attack_outputs))  # True labels for attack outputs\n","    return scores_norm, predictions, y_test\n","\n","hackrf1_scores, svmhackrf1_pred, hackrf1_true = evaluate_attack_outputs(attack1_outputs, 'HackRF1')\n","hackrf2_scores, svmhackrf2_pred, hackrf2_true = evaluate_attack_outputs(attack2_outputs, 'HackRF2')\n","\n","combined_predictions = np.concatenate([legitimate_predictions,svmhackrf1_pred, svmhackrf2_pred])\n","true_labels = np.concatenate([np.zeros_like(legitimate_predictions), hackrf1_true, hackrf2_true])\n","\n","plot_data = [\n","    legitimate_scores_norm,\n","    hackrf1_scores,\n","    hackrf2_scores\n","]\n","\n","plt.figure(figsize=(8, 10))\n","colors = sns.color_palette(\"Set1\", n_colors=3)\n","\n","sns.boxplot(data=plot_data, width=0.3, palette=colors, linewidth=2.5)\n","plt.axhline(y=thresholdsvm, color='g', linestyle='--', linewidth=2, label='Threshold')\n","plt.xticks([0, 1, 2], ['Legitimate Device', 'HackRF#1', 'HackRF#2'], fontsize=14)\n","plt.yticks(fontsize=14)\n","plt.ylabel('Normalized Score', fontsize=16)\n","plt.title('SVM', fontsize=18)\n","plt.legend(fontsize=14)\n","plt.grid(True, linestyle='--', linewidth=1)\n","plt.show()\n","\n","print(\"Classification Report for SVM\")\n","print(classification_report(true_labels, combined_predictions, target_names=['Legitimate', 'Attack']))\n","\n","cm = confusion_matrix(true_labels, combined_predictions)\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Legitimate', 'Attack'], yticklabels=['Legitimate', 'Attack'])\n","\n","\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","clf = svm.OneClassSVM(kernel='rbf',nu=0.1)\n","clf.fit(X_train)\n","scores = clf.decision_function(X_test)"]},{"cell_type":"markdown","metadata":{"id":"ZhfApsd90RWi"},"source":["### ResNet with Constellation dataset:"]},{"cell_type":"markdown","metadata":{"id":"2Qjxhsa30RWi"},"source":["### ResNet with FFT dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jlNWvQ2Z0RWj","outputId":"4b567e3b-c01e-400c-868c-7d8a6a811a44"},"outputs":[],"source":["signal,label = reference_loader.dataset[0]\n","print(signal.shape)\n","signal = signal.permute(1, 2, 0)\n","signal = signal.numpy()\n","import matplotlib.pyplot as plt\n","plt.imshow(signal)\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i0BxD6380RWk","outputId":"49c0fca2-4f8b-4d01-a057-ca5dd15330c7"},"outputs":[],"source":["signal,label = reference_loader.dataset[0]\n","print(signal.shape)\n","signal = signal.permute(1, 2, 0)\n","signal = signal.numpy()\n","import matplotlib.pyplot as plt\n","plt.imshow(signal)\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nlOb96Rx0RWk","outputId":"9decbe88-9a6b-44e9-8c5f-d415cc69fcb8"},"outputs":[],"source":["legitimate_outputs[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nk37OXUK0RWk","outputId":"9ff1e2af-3daf-4c04-8dcf-27bdc657d66b"},"outputs":[],"source":["# plot the correlation matrix with the legitimate and attack signals\n","import seaborn as sns\n","\n","def plot_correlation_matrix(data, title):\n","    corr = np.corrcoef(data)\n","    sns.heatmap(corr, xticklabels=False, yticklabels=False)\n","    plt.title(title)\n","    plt.show()\n","\n","combined_outputs = np.concatenate([legitimate_outputs,augmented_legitimate_outputs, attack1_outputs, attack2_outputs])\n","\n","plot_correlation_matrix(combined_outputs, 'Legitimate and Attack Signals Correlation Matrix')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YWZRFNpr0RWl","outputId":"eb98cbc5-5889-4f4e-a88c-86d60acfe207"},"outputs":[],"source":["# DO pca\n","from sklearn.decomposition import PCA\n","\n","def plot_pca(data, title):\n","    pca = PCA(n_components=400)\n","    principal_components = pca.fit_transform(data)\n","    plt.scatter(principal_components[:len(legitimate_outputs), 2], principal_components[:len(legitimate_outputs), 3], label='Legitimate',s=10)\n","    plt.scatter(principal_components[len(legitimate_outputs):, 2], principal_components[len(legitimate_outputs):, 3], label='Attack',s=10)\n","    plt.title(title)\n","    plt.show()\n","    return principal_components\n","\n","combined_pca = plot_pca(combined_outputs, 'PCA')\n","legitimate_pca = combined_pca[:len(legitimate_outputs)]\n","augmented_legitimate_pca = combined_pca[len(legitimate_outputs):len(augmented_legitimate_outputs)]\n","attack1_pca = combined_pca[len(legitimate_outputs) + len(augmented_legitimate_outputs):len(legitimate_outputs) + len(augmented_legitimate_outputs) +len(attack1_dataset)]\n","attack2_pca = combined_pca[len(legitimate_outputs) + len(augmented_legitimate_outputs)+len(attack1_dataset):]\n","print(len(legitimate_pca), len(attack1_pca), len(attack2_pca))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"om0LIizi0RWn","outputId":"b0cda708-8ab3-4063-82bb-064d2dc88273"},"outputs":[],"source":["# One class SVM\n","import numpy as np\n","from sklearn import svm\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import classification_report\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","scaler = StandardScaler()\n","\n","def train_svm_and_get_scores(X_train, X_test):\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","    clf = svm.OneClassSVM(kernel='rbf',nu=0.04)\n","    clf.fit(X_train)\n","    scores = clf.decision_function(X_test)\n","    return scores\n","\n","X_train, X_test = train_test_split(augmented_legitimate_pca, test_size=0.3, random_state=42)\n","\n","aug_legitimate_scores = train_svm_and_get_scores(X_train, X_test)\n","\n","mu = np.mean(aug_legitimate_scores)\n","sigma = np.std(aug_legitimate_scores)\n","\n","legitimate_scores = train_svm_and_get_scores(X_train, legitimate_pca)\n","\n","legitimate_scores_norm = np.abs((legitimate_scores - mu) / sigma)\n","\n","thresholdsvm = np.percentile(legitimate_scores_norm, 95)\n","legitimate_predictions = (legitimate_scores_norm > thresholdsvm).astype(int)\n","\n","def evaluate_attack_outputs(attack_outputs, device_name):\n","    scores = train_svm_and_get_scores(X_train, attack_outputs)\n","    scores_norm = np.abs((scores - mu) / sigma)\n","    predictions = (scores_norm > thresholdsvm).astype(int)\n","    y_test = np.ones(len(attack_outputs))  # True labels for attack outputs\n","    return scores_norm, predictions, y_test\n","\n","hackrf1_scores, svmhackrf1_pred, hackrf1_true = evaluate_attack_outputs(attack1_pca, 'HackRF1')\n","hackrf2_scores, svmhackrf2_pred, hackrf2_true = evaluate_attack_outputs(attack2_pca, 'HackRF2')\n","\n","combined_predictions = np.concatenate([legitimate_predictions,svmhackrf1_pred, svmhackrf2_pred])\n","true_labels = np.concatenate([np.zeros_like(legitimate_predictions), hackrf1_true, hackrf2_true])\n","\n","plot_data = [\n","    legitimate_scores_norm,\n","    hackrf1_scores,\n","    hackrf2_scores\n","]\n","\n","plt.figure(figsize=(8, 10))\n","colors = sns.color_palette(\"Set1\", n_colors=3)\n","\n","sns.boxplot(data=plot_data, width=0.3, palette=colors, linewidth=2.5)\n","plt.axhline(y=thresholdsvm, color='g', linestyle='--', linewidth=2, label='Threshold')\n","plt.xticks([0, 1, 2], ['Legitimate Device', 'HackRF#1', 'HackRF#2'], fontsize=14)\n","plt.yticks(fontsize=14)\n","plt.ylabel('Normalized Score', fontsize=16)\n","plt.title('SVM', fontsize=18)\n","plt.legend(fontsize=14)\n","plt.grid(True, linestyle='--', linewidth=1)\n","plt.show()\n","\n","print(\"Classification Report for SVM\")\n","print(classification_report(true_labels, combined_predictions, target_names=['Legitimate', 'Attack']))\n","\n","cm = confusion_matrix(true_labels, combined_predictions)\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Legitimate', 'Attack'], yticklabels=['Legitimate', 'Attack'])"]},{"cell_type":"markdown","metadata":{"id":"JtnFhiwY0RWn"},"source":["### Dataset Creation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WUpyDtS-0RWn"},"outputs":[],"source":["# datasets: legitimate, reconstructed, attack, augmented legitimate signals\n","import numpy as np\n","\n","datasets_directory = '../datasets/signals/'\n","\n","with open(datasets_directory + 'reconstructed.npy','rb') as f:\n","    reconstructed_attack = []\n","    signal = np.load(f)\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            reconstructed_attack.append(signal)\n","        except:\n","            break\n","\n","with open(datasets_directory + 'legitimate.npy','rb') as f:\n","    legitimate = []\n","    signal = np.load(f)\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            legitimate.append(signal)\n","        except:\n","            break\n","\n","with open(datasets_directory + 'attack1.npy','rb') as f:\n","    attack1 = []\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            attack1.append(signal)\n","        except:\n","            break\n","\n","with open(datasets_directory + 'attack2.npy','rb') as f:\n","    attack2 = []\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            attack2.append(signal)\n","        except:\n","            break\n","\n","with open(datasets_directory + 'augmented_legitimate.npy','rb') as f:\n","    augmented_legitimate = []\n","    while True:\n","        try:\n","            signal = np.load(f)\n","            augmented_legitimate.append(signal)\n","        except:\n","            break\n","\n","augmented_legitimate = [(signal, 0) for signal in augmented_legitimate]\n","reconstructed_attack = [(signal, 1) for signal in reconstructed_attack]\n","attack1 = [(signal, 1) for signal in attack1]\n","attack2 = [(signal, 1) for signal in attack2]\n","legitimate = [(signal, 0) for signal in legitimate]\n","reference_dataset = augmented_legitimate + reconstructed_attack\n","target_dataset = augmented_legitimate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yY1bUw8Q0RWp","outputId":"2fe59863-9c75-4832-a1b9-8a6fda9ac91e"},"outputs":[],"source":["signal"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fwQOwQno0RWp"},"outputs":[],"source":["from helpers.fft_gen import gen_fft_dataset\n","\n","legitimate_fft = gen_fft_dataset(legitimate)\n","reconstructed_attack_fft = gen_fft_dataset(reconstructed_attack)\n","attack1_fft = gen_fft_dataset(attack1)\n","attack2_fft = gen_fft_dataset(attack2)\n","augmented_legitimate_fft = gen_fft_dataset(augmented_legitimate)\n","\n","fft_directory = '../datasets/fft/'\n","\n","with open(fft_directory + 'legitimate.npy', 'wb') as f:\n","    for signal in legitimate_fft:\n","        np.save(f, signal[0])\n","\n","with open(fft_directory + 'reconstructed.npy', 'wb') as f:\n","    for signal in reconstructed_attack_fft:\n","        np.save(f, signal[0])\n","\n","with open(fft_directory + 'attack1.npy', 'wb') as f:\n","    for signal in attack1_fft:\n","        np.save(f, signal[0])\n","\n","with open(fft_directory + 'attack2.npy', 'wb') as f:\n","    for signal in attack2_fft:\n","        np.save(f, signal[0])\n","\n","with open(fft_directory + 'augmented_legitimate.npy', 'wb') as f:\n","    for signal in augmented_legitimate_fft:\n","        np.save(f, signal[0])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cn1MAykI0RWp"},"outputs":[],"source":["from helpers.constellation_gen import gen_constellation_dataset\n","legitimate_constellation = gen_constellation_dataset(legitimate)\n","reconstructed_attack_constellation = gen_constellation_dataset(reconstructed_attack)\n","attack1_constellation = gen_constellation_dataset(attack1)\n","attack2_constellation = gen_constellation_dataset(attack2)\n","augmented_legitimate_constellation = gen_constellation_dataset(augmented_legitimate)\n","\n","constellation_directory = '../datasets/constellation/'\n","\n","with open(constellation_directory + 'legitimate.npy', 'wb') as f:\n","    for signal in legitimate_constellation:\n","        np.save(f, signal[0])\n","\n","with open(constellation_directory + 'reconstructed.npy', 'wb') as f:\n","    for signal in reconstructed_attack_constellation:\n","        np.save(f, signal[0])\n","\n","with open(constellation_directory + 'attack1.npy', 'wb') as f:\n","    for signal in attack1_constellation:\n","        np.save(f, signal[0])\n","\n","with open(constellation_directory + 'attack2.npy', 'wb') as f:\n","    for signal in attack2_constellation:\n","        np.save(f, signal[0])\n","\n","with open(constellation_directory + 'augmented_legitimate.npy', 'wb') as f:\n","    for signal in augmented_legitimate_constellation:\n","        np.save(f, signal[0])\n"]},{"cell_type":"markdown","metadata":{},"source":["### Loss plot"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"5fxIAtaT0RWp"},"outputs":[],"source":["import pickle\n","import torch\n","import torch.nn as nn\n","import pytorchcv\n","\n","class DOCMobileNetV1(nn.Module):\n","    def __init__(self, num_classes):\n","        super(DOCMobileNetV1, self).__init__()\n","        # Load pretrained MobileNetV1 from pytorchcv\n","        self.mobilenet = ptcv_get_model(\"mobilenet_w1\", pretrained=True)\n","        num_features = self.mobilenet.output.in_features\n","        self.mobilenet.output = nn.Linear(num_features, num_classes)\n","        self.losses = []\n","\n","    def forward(self, x):\n","        return self.mobilenet(x)\n","    \n","class DOCMobileNetV2(nn.Module):\n","    def __init__(self, num_classes):\n","        super(DOCMobileNetV2, self).__init__()\n","        self.mobilenet = models.mobilenet_v2(pretrained=True)\n","        num_features = self.mobilenet.classifier[1].in_features\n","        self.mobilenet.classifier[1] = nn.Linear(num_features, num_classes)\n","        self.losses = []\n","\n","    def forward(self, x):\n","        return self.mobilenet(x)\n","\n","with open('mobilenetv1_fft_aug.pkl','rb') as f:\n","  mb1 = pickle.load(f)\n","\n","with open('mobilenetv2_fft_aug.pkl','rb') as f:\n","  mb2 = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","plt.rcParams.update({\n","    'font.size': 14,           # General font size\n","    'axes.titlesize': 18,      # Title font size\n","    'axes.labelsize': 16,      # Axis label font size\n","    'legend.fontsize': 14,     # Legend font size\n","    'xtick.labelsize': 12,     # X-axis tick font size\n","    'ytick.labelsize': 12      # Y-axis tick font size\n","})\n","\n","compactness_loss = [loss[1] for epoch_losses in mb1.losses for loss in epoch_losses]\n","descriptiveness_loss = [loss[2] for epoch_losses in mb1.losses for loss in epoch_losses]\n","distillation_loss = [loss[0] for epoch_losses in mb1.losses for loss in epoch_losses]\n","iterations = np.arange(1, len(distillation_loss) + 1)\n","fig, ax1 = plt.subplots(figsize=(8, 6))\n","ax1.plot(iterations, compactness_loss, 'g--', label='Compactness Loss')\n","ax1.plot(iterations, descriptiveness_loss, 'b-.', label='Descriptiveness Loss')\n","ax1.plot(iterations, distillation_loss, 'm-', label='Distillation Loss')\n","ax1.set_xlabel('Training Iterations')\n","ax1.set_ylabel('Loss', color='blue')\n","ax1.tick_params(axis='y', labelcolor='blue')\n","\n","lines, labels = ax1.get_legend_handles_labels()\n","ax1.legend(lines, labels, loc='center right')\n","# plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n","plt.xscale('log')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","plt.rcParams.update({\n","    'font.size': 14,           # General font size\n","    'axes.titlesize': 18,      # Title font size\n","    'axes.labelsize': 16,      # Axis label font size\n","    'legend.fontsize': 14,     # Legend font size\n","    'xtick.labelsize': 12,     # X-axis tick font size\n","    'ytick.labelsize': 12      # Y-axis tick font size\n","})\n","\n","compactness_loss = [loss[1] for epoch_losses in mb2.losses for loss in epoch_losses]\n","descriptiveness_loss = [loss[2] for epoch_losses in mb2.losses for loss in epoch_losses]\n","distillation_loss = [loss[0] for epoch_losses in mb2.losses for loss in epoch_losses]\n","iterations = np.arange(1, len(distillation_loss) + 1)\n","fig, ax1 = plt.subplots(figsize=(8, 6))\n","ax1.plot(iterations, compactness_loss, 'g--', label='Compactness Loss')\n","ax1.plot(iterations, descriptiveness_loss, 'b-.', label='Descriptiveness Loss')\n","ax1.plot(iterations, distillation_loss, 'm-', label='Distillation Loss')\n","ax1.set_xlabel('Training Iterations')\n","ax1.set_ylabel('Loss', color='blue')\n","ax1.tick_params(axis='y', labelcolor='blue')\n","\n","lines, labels = ax1.get_legend_handles_labels()\n","ax1.legend(lines, labels, loc='center right')\n","# plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n","plt.xscale('log')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":0}
